# Chinese Text Annotator (zho-annotator)

ğŸ‡¨ğŸ‡³ Intelligent Chinese text annotator with pinyin and zhuyin support, featuring automatic text normalization and multiple output formats.

## Features

- **Multi-format Output**: Inline, JSON, brackets, ruby (HTML), and table formats
- **Dual Annotation Styles**: Pinyin, Zhuyin, or both
- **Automatic Text Normalization**: Built-in conversion of Kangxi radicals and character variants
- **Confidence Scoring**: Built-in confidence thresholds for quality control
- **Traditional/Simplified Support**: Automatic script detection and preference settings
- **Fast Processing**: Dictionary-based lookup with 800K+ entries
- **Cross-platform**: Pure Rust implementation
- **No AI/ML Dependencies**: Lightweight dictionary-based approach

## Installation

### From Source
```bash
git clone <repository-url>
cd zho-annotator
cargo build --release
```

### Prerequisites
You'll need the processed dictionary file (`processed_dictionary.json`) in the project root. This file contains the pronunciation data and is required for the annotator to function.

## Quick Start

```bash
# Basic annotation
./target/release/zho-annotator -t "ä½ å¥½ä¸–ç•Œ"
# Output: ä½ å¥½(nÇhÇo)ä¸–ç•Œ(shÃ¬jiÃ¨)

# JSON output with confidence scores
./target/release/zho-annotator -t "ä½ å¥½ä¸–ç•Œ" --format json --show-confidence

# Traditional Chinese with automatic normalization
./target/release/zho-annotator -t "â½…â¾¯å•é¡Œ" --traditional
# Automatically normalizes â½…â¾¯ â†’ æ–¹é¢, then annotates

# Zhuyin annotation style
./target/release/zho-annotator -t "ä½ å¥½ä¸–ç•Œ" --style zhuyin
# Output: ä½ å¥½(ã„‹ã„§Ë‡ã„ã„ Ë‡)ä¸–ç•Œ(ã„•Ë‹ã„ã„§ã„Ë‹)
```

## Usage

### Command Line Options

```bash
zho-annotator [OPTIONS]

Options:
  -t, --text <TEXT>             Chinese text to annotate
  -f, --file <FILE>             File containing Chinese text to annotate
      --stdin                   Read text from standard input
  -d, --dict <PATH>             Path to processed dictionary file [default: processed_dictionary.json]
      --format <FORMAT>         Output format: inline, json, brackets, ruby, table [default: inline]
      --style <STYLE>           Annotation style: pinyin, zhuyin, both [default: pinyin]
      --confidence <THRESHOLD>  Minimum confidence threshold (0.0-1.0) [default: 0.3]
      --show-alternatives       Show alternative pronunciations
      --show-confidence         Show confidence scores
      --traditional             Prefer traditional Chinese characters
      --examples                Show usage examples
  -h, --help                    Print help
  -V, --version                 Print version
```

### Output Formats

#### Inline (Default)
```bash
./target/release/zho-annotator -t "æˆ‘çˆ±ä¸­å›½"
# Output: æˆ‘(wÇ’)çˆ±(Ã i)ä¸­å›½(zhÅngguÃ³)
```

#### JSON
```bash
./target/release/zho-annotator -t "ä½ å¥½" --format json
# Output: {"segments": [{"text": "ä½ å¥½", "pinyin": "nÇ hÇo", ...}]}
```

#### Brackets
```bash
./target/release/zho-annotator -t "ä½ å¥½" --format brackets
# Output: ä½ [nÇ]å¥½[hÇo]
```

#### Ruby (HTML)
```bash
./target/release/zho-annotator -t "ä½ å¥½" --format ruby
# Output: <ruby>ä½ <rt>nÇ</rt></ruby><ruby>å¥½<rt>hÇo</rt></ruby>
```

#### Table
```bash
./target/release/zho-annotator -t "ä½ å¥½" --format table
# Output: Position	Text	Pinyin	Zhuyin	Confidence	Alternatives
```

#### Rows (Two-line aligned)
```bash
./target/release/zho-annotator -t "ä½ å¥½ä¸–ç•Œ" --format rows
# Output:
# ä½ å¥½  ä¸–ç•Œ
# nÇhÇo shÃ¬jiÃ¨
```

### Script Specification

**Important:** For accurate pronunciation, specify the script when dealing with ambiguous text:

#### Traditional Chinese
```bash
./target/release/zho-annotator -t "æ¿€å…‰å”±ç‰‡" --traditional
# Output: æ¿€å…‰å”±ç‰‡(jÄ«guÄngchÃ ngpiÃ n) - Mainland pronunciation
```

#### Auto-detection (Default)
```bash
./target/release/zho-annotator -t "æ¿€å…‰å”±ç‰‡"
# Output: æ¿€å…‰å”±ç‰‡(lÃ©ishÃ¨chÃ ngpiÃ n) - May use Taiwan pronunciation
```

**Why this matters:**
- Some terms exist in both Traditional and Simplified forms with different pronunciations
- Auto-detection may choose Taiwan pronunciations for ambiguous text
- Use `--traditional` flag when your input is Traditional Chinese for consistent results

### Advanced Usage

#### File Processing
```bash
# Process a text file
./target/release/zho-annotator -f input.txt --format json > output.json

# Process from stdin
echo "ä½ å¥½ä¸–ç•Œ" | ./target/release/zho-annotator --stdin --format table
```

#### Quality Control
```bash
# High confidence only
./target/release/zho-annotator -t "å¤æ‚å¥å­" --confidence 0.8

# Show alternatives and confidence
./target/release/zho-annotator -t "å¤æ‚å¥å­" --show-alternatives --show-confidence
```

#### Text Normalization
```bash
# Automatic normalization of Kangxi radicals and variants
./target/release/zho-annotator -t "â½…â¾¯å•é¡Œ"
# Automatically converts â½…â¾¯ â†’ æ–¹é¢ for better lookup
```

## Library Usage

### Rust
```rust
use zho_annotator::production_annotator::{ProductionAnnotator, AnnotationConfig, OutputFormat, AnnotationStyle};

let config = AnnotationConfig {
    output_format: OutputFormat::Json,
    annotation_style: AnnotationStyle::Pinyin,
    confidence_threshold: 0.5,
    show_alternatives: true,
    show_confidence: true,
    use_traditional: false,
};

let annotator = ProductionAnnotator::new("processed_dictionary.json", config)?;
let segments = annotator.annotate("ä½ å¥½ä¸–ç•Œ")?;
let output = annotator.format_output(&segments);
```

## Project Structure

```
zho-annotator/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ main.rs                 # CLI entry point
â”‚   â”œâ”€â”€ lib.rs                  # Library exports
â”‚   â”œâ”€â”€ production_annotator.rs # Main annotation logic
â”‚   â”œâ”€â”€ dictionary.rs           # Dictionary loading and lookup
â”‚   â””â”€â”€ dict_processor.rs       # Dictionary processing tool
â”œâ”€â”€ processed_dictionary.json   # Required: pronunciation data (800K+ entries)
â”œâ”€â”€ Cargo.toml                 # Project configuration
â””â”€â”€ README.md                  # This file
```

## Dictionary Processing

The project includes a dictionary processor to create optimized lookup files:

```bash
cargo run --bin dict-processor
```

This processes `enhanced_dictionary.json` into the optimized `processed_dictionary.json` format.

## Performance

- **Dictionary Size**: 800K+ entries
- **Processing Speed**: ~1000 characters/second
- **Memory Usage**: ~50MB for dictionary loading
- **Binary Size**: ~1MB (release build)

## License

MIT License - see LICENSE file for details.
